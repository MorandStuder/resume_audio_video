import os
import json
from pathlib import Path
from openai import OpenAI
import anthropic
from transformers import pipeline
from mistralai.client import MistralClient
from google.cloud import aiplatform
from vertexai.language_models import TextGenerationModel


def load_api_key():
    """Charge la cl√© API depuis le fichier config"""
    config_file = Path("config.json")
    
    if config_file.exists():
        with open(config_file, "r") as f:
            config = json.load(f)
            api_key = config.get("OPENAI_API_KEY", "")
            if api_key:
                return api_key
    
    # Si pas de cl√©, demander √† l'utilisateur
    api_key = input("Entrez votre cl√© API OpenAI: ").strip()
    
    # Sauvegarder la cl√© pour la prochaine fois
    with open(config_file, "w") as f:
        json.dump({"OPENAI_API_KEY": api_key}, f)
    
    return api_key


def get_model_choice():
    """Permet √† l'utilisateur de choisir le mod√®le"""
    print("\nChoisissez le mod√®le √† utiliser:")
    print("1. GPT-3.5-turbo (OpenAI - payant mais rapide)")
    print("2. Claude-2 (Anthropic - alternative √† GPT)")
    print("3. BART (Hugging Face - gratuit, local)")
    print("4. GPT-3.5-turbo-16k (OpenAI - plus de contexte)")
    print("5. Mistral Large (Fran√ßais, tr√®s performant)")
    print("6. Google PaLM 2 (Via Vertex AI)")
    
    choice = input("\nVotre choix (1-6): ").strip()
    return choice


def summarize_with_openai(text, client, model="gpt-3.5-turbo"):
    """R√©sum√© avec OpenAI"""
    response = client.chat.completions.create(
        model=model,
        messages=[
            {
                "role": "system",
                "content": "Tu es un assistant qui r√©sume des transcriptions."
            },
            {
                "role": "user",
                "content": f"R√©sume ce texte en fran√ßais de mani√®re concise et structur√©e:\n\n{text}"
            }
        ]
    )
    return response.choices[0].message.content


def summarize_with_claude(text, client):
    """R√©sum√© avec Claude"""
    response = client.messages.create(
        model="claude-2",
        max_tokens=1000,
        messages=[
            {
                "role": "user",
                "content": f"R√©sume ce texte en fran√ßais de mani√®re concise et structur√©e:\n\n{text}"
            }
        ]
    )
    return response.content


def summarize_with_bart(text):
    """R√©sum√© avec BART"""
    summarizer = pipeline(
        "summarization",
        model="facebook/bart-large-cnn",
        tokenizer="facebook/bart-large-cnn"
    )
    
    # BART a une limite de tokens, donc on d√©coupe si n√©cessaire
    max_chunk_length = 1024
    chunks = [text[i:i + max_chunk_length] for i in range(0, len(text), max_chunk_length)]
    
    summaries = []
    for chunk in chunks:
        summary = summarizer(chunk, max_length=130, min_length=30, do_sample=False)
        summaries.append(summary[0]['summary_text'])
    
    return " ".join(summaries)


def summarize_with_mistral(text, api_key):
    """R√©sum√© avec Mistral AI"""
    client = MistralClient(api_key=api_key)
    
    response = client.chat(
        model="mistral-large-latest",
        messages=[
            {
                "role": "system",
                "content": "Tu es un assistant qui r√©sume des transcriptions."
            },
            {
                "role": "user",
                "content": "R√©sume ce texte en fran√ßais de mani√®re structur√©e:"
                          f"\n\n{text}"
            }
        ]
    )
    return response.messages[0].content


def summarize_with_google(text):
    """R√©sum√© avec Google PaLM"""
    aiplatform.init(project="votre-projet")
    model = TextGenerationModel.from_pretrained("text-bison@001")
    
    prompt = (
        "R√©sume le texte suivant en fran√ßais de mani√®re structur√©e:"
        f"\n\n{text}"
    )
    
    response = model.predict(prompt, temperature=0.2)
    return response.text


def load_mistral_key():
    """Charge la cl√© API Mistral"""
    config_file = Path("config.json")
    
    if config_file.exists():
        with open(config_file, "r") as f:
            config = json.load(f)
            api_key = config.get("MISTRAL_API_KEY", "")
            if api_key:
                return api_key
    
    api_key = input("Entrez votre cl√© API Mistral: ").strip()
    
    # Mettre √† jour le fichier config
    config = {}
    if config_file.exists():
        with open(config_file, "r") as f:
            config = json.load(f)
    config["MISTRAL_API_KEY"] = api_key
    with open(config_file, "w") as f:
        json.dump(config, f)
    
    return api_key


def test_summary():
    """Test la partie r√©sum√© avec diff√©rents mod√®les"""
    print("=== TEST DU R√âSUM√â ===")
    
    # V√©rifier le fichier de transcription
    transcript_path = "transcriptions/transcription_complete.txt"
    if not os.path.exists(transcript_path):
        print("‚ùå Erreur: Fichier transcription_complete.txt non trouv√©")
        return
    
    # Choix du mod√®le
    choice = get_model_choice()
    
    # Configuration selon le choix
    if choice in ['1', '4']:
        client = OpenAI(api_key=load_api_key())
        model = "gpt-4o"
        summarize_func = lambda text: summarize_with_openai(text, client, model)
    elif choice == '2':
        client = anthropic.Anthropic(api_key=load_anthropic_key())
        summarize_func = lambda text: summarize_with_claude(text, client)
    elif choice == '5':
        api_key = load_mistral_key()
        summarize_func = lambda text: summarize_with_mistral(text, api_key)
    elif choice == '6':
        summarize_func = summarize_with_google
    else:
        summarize_func = summarize_with_bart
    
    # Lire la transcription
    with open(transcript_path, "r", encoding="utf-8") as f:
        full_text = f.read()
    
    # Diviser en segments
    segments = full_text.split("="*50)
    segments = [s.strip() for s in segments if s.strip()]
    
    # Cr√©er le dossier des r√©sum√©s
    output_directory = "resumes"
    os.makedirs(output_directory, exist_ok=True)
    
    try:
        # R√©sumer chaque segment
        summaries = []
        for i, text in enumerate(segments, 1):
            print(f"\nR√©sum√© du segment {i}...")
            
            summary = summarize_func(text)
            
            output_path = os.path.join(output_directory, f"resume_{i:02d}.txt")
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(summary)
            
            summaries.append(summary)
            print(f"‚úÖ Segment {i} r√©sum√©")
        
        # R√©sum√© global
        print("\nCr√©ation du r√©sum√© global...")
        all_text = "\n\n".join(summaries)
        global_summary = summarize_func(all_text)
        
        with open(os.path.join(output_directory, "resume_global.txt"), "w", 
                  encoding="utf-8") as f:
            f.write(global_summary)
        
        print("\n‚úÖ Traitement termin√©!")
        print(f"üìÇ R√©sum√©s sauvegard√©s dans: {os.path.abspath(output_directory)}")
        
    except Exception as e:
        print(f"\n‚ùå Une erreur s'est produite: {str(e)}")
    
    input("\nAppuyez sur Entr√©e pour fermer...")


if __name__ == "__main__":
    test_summary() 